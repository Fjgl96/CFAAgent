# requirements_local_embeddings.txt
# OPCIONAL: Dependencias para usar embeddings locales (sentence-transformers)
#
# üéØ INSTALAR SOLO SI QUIERES USAR SEMANTIC CHUNKING LOCAL ($0 costo)
#
# Instalaci√≥n:
# pip install -r admin/requirements_local_embeddings.txt
#
# Uso despu√©s de instalar:
# python admin/generate_index_semantic_local.py
#
# ========================================
# Embeddings Locales con HuggingFace
# ========================================

# LlamaIndex integration con HuggingFace embeddings
llama-index-embeddings-huggingface>=0.1.0

# Sentence-transformers (modelos de embeddings locales)
sentence-transformers>=2.2.0

# Transformers de HuggingFace (dependencia de sentence-transformers)
transformers>=4.30.0

# PyTorch (backend para modelos - CPU version)
# NOTA: Si tienes GPU NVIDIA, instala manualmente con CUDA support:
# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
torch>=2.0.0

# ========================================
# Utilidades
# ========================================

# Progress bars para downloads de modelos
tqdm>=4.65.0

# ========================================
# NOTAS IMPORTANTES
# ========================================
#
# 1. Tama√±o de descarga:
#    - all-MiniLM-L6-v2: ~90 MB
#    - all-mpnet-base-v2: ~420 MB
#    - bge-large-en-v1.5: ~1.34 GB
#
# 2. Los modelos se descargan autom√°ticamente la primera vez desde HuggingFace Hub
#    y se cachean localmente en ~/.cache/huggingface/
#
# 3. Requisitos de sistema para indexaci√≥n:
#    - RAM m√≠nima: 4 GB (8 GB recomendado)
#    - Espacio disco: 2-5 GB (modelos + cach√©)
#    - CPU: Cualquier CPU moderno (i5 o superior recomendado)
#    - GPU: Opcional pero acelera 10-20x
#
# 4. Tiempo de indexaci√≥n (5 libros CFA, CPU i5):
#    - all-MiniLM-L6-v2: ~35-45 minutos
#    - all-mpnet-base-v2: ~60-90 minutos
#    - bge-large-en-v1.5: ~90-120 minutos
#
# 5. Si tienes problemas con versiones, puedes instalar versiones espec√≠ficas:
#    sentence-transformers==2.2.2
#    transformers==4.30.2
#    torch==2.0.1
